{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5_question_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM6VLzhzz5yEYAqAotne0iv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vegarab/msc-qg/blob/master/notebooks/T5_question_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhXuyVbLi6oK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b6284601-20be-42b2-9e25-311cb03fcb5a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbsKJ2aIjdOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "1f4098e6-2a85-4521-a22d-5335f121ec07"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 2.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b04008a9d15f3d5312bed6960ef9d7d77343724a536061226dc953cbaaa179fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lysVSulDkUvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2vrIagHko8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3fa4acb-1572-424b-d52b-e9528cc604a9"
      },
      "source": [
        "!nvidia_smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: nvidia_smi: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukPyk3HukrwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class T5QuestionGenerator():\n",
        "    def __init__(self, max_len=512, q_len=64):\n",
        "        model_file = './drive/My Drive/msc-qg/models/t5_squad_exploration_2/'\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(model_file)\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.MAX_LEN = max_len\n",
        "        self.Q_LEN = q_len\n",
        "\n",
        "    def generate(self, context, answer):\n",
        "        source = self._encode_input(context, answer)\n",
        "\n",
        "        source_ids = source['input_ids'].cuda().to(dtype=torch.long)\n",
        "        source_mask = source['attention_mask'].cuda().to(dtype=torch.long)\n",
        "        \n",
        "        generated_ids = self.model.generate(\n",
        "            input_ids=source_ids,\n",
        "            attention_mask=source_mask,\n",
        "            max_length=self.MAX_LEN,\n",
        "            num_beams=2,\n",
        "            repition_penalty=2.5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        question = self._decode_question(generated_ids)\n",
        "\n",
        "        return 'question' + question\n",
        "\n",
        "    def _encode_input(self, context, answer):\n",
        "        context = 'context: ' + context\n",
        "        answer = 'answer: ' + answer\n",
        "        _input = answer + ' ' + context + ' </s>'\n",
        "\n",
        "\n",
        "        return self.tokenizer.batch_encode_plus([_input],\n",
        "                                                max_length=self.MAX_LEN,\n",
        "                                                pad_to_max_length=True,\n",
        "                                                truncation=True,\n",
        "                                                return_tensors='pt')\n",
        "\n",
        "    def _decode_question(self, generated_ids):\n",
        "        # Assuming only one input -> one output\n",
        "        generated_id = generated_ids.squeeze()\n",
        "        predicted = self.tokenizer.decode(generated_id, \n",
        "                                          skip_special_tokens=True,\n",
        "                                          clean_up_tokenization_spaces=True)\n",
        "        return predicted\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KDUN8O9po6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = T5QuestionGenerator()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSptfNZdpwJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "d2861a04-6917-4bda-c287-e96da28e7442"
      },
      "source": [
        "# https://www.inspera.com/about\n",
        "context = \"\"\"Inspera Assessment was created to provide test takers with equal opportunities \n",
        "             and to enable them to prove their skills in an authentic way. We empower universities, \n",
        "             awarding organisations, governments, municipalities and schools to deliver secure, \n",
        "             standardised tests, open- and closed- book exams, as well as formative and diagnostics \n",
        "             tests. Inspera offers the most innovative, reliable and secure online assessment platform, \n",
        "             accompanied with the necessary expertise to ensure successful organisation-wide \n",
        "             implementation and rollout. Founded in 1999, we are a dedicated international team of more \n",
        "             than 90 EdTech entrepreneurs on a mission to impact education on a global scale. \"\"\"\n",
        "\n",
        "answers = ['1999', 'an online assessment platform', 'governments', \n",
        "           'international team', 'an international team', 'global']\n",
        "\n",
        "for answer in answers:\n",
        "    print('answer: ' + answer)\n",
        "    print(generator.generate(context, answer) + '\\n')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "answer: 1999\n",
            "question: When was Inspera Assessment founded?\n",
            "\n",
            "answer: an online assessment platform\n",
            "question: What type of platform does Inspera offer?\n",
            "\n",
            "answer: governments\n",
            "question: Along with universities and awarding organisations, what other organization does Inspera Assessment work with?\n",
            "\n",
            "answer: international team\n",
            "question: What type of team is Inspera?\n",
            "\n",
            "answer: an international team\n",
            "question: What is Inspera Assessment's mission?\n",
            "\n",
            "answer: global\n",
            "question: On what scale is Inspera Assessment a dedicated team of 90 EdTech entrepreneurs?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LSlIuIDrAD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5685b03d-2e28-4314-800e-31fe35913f0c"
      },
      "source": [
        "# https://www.ielts.org/-/media/pdfs/pb-sample-test-materials/academic-reading-sample-task-multiple-choice-one-answer.ashx?la=en\n",
        "context = \"\"\"The general assumption is that older workers are paid more in spite of, rather \n",
        "             than because of, their productivity. That might partly explain why, when employers \n",
        "             are under pressure to cut costs, they persuade a 55-year old to take early retirement. \n",
        "             Take away seniority-based pay scales, and older workers may become a much more \n",
        "             attractive employment proposition. But most employers and many workers are uncomfortable \n",
        "             with the idea of reducing someone’s pay in later life –although manual workers on piece-rates \n",
        "             often earn less as they get older. So retaining the services of older workers may mean \n",
        "             employing them in different ways.\n",
        "             \n",
        "             One innovation was devised by IBM Belgium. Faced with the need to cut staff costs, and having \n",
        "             decided to concentrate cuts on 55 to 60-year olds, IBM set up a separate company called Skill \n",
        "             Team, which re-employed any of the early retired who wanted to go on working up to the age of \n",
        "             60. An employee who joined Skill Team at the age of 55 on a five-year contract would work for \n",
        "             58% of his time, over the full period, for 88% of his last IBM salary. The company offered \n",
        "             services to IBM, thus allowing it to retain access to some of the intellectual capital it \n",
        "             would otherwise have lost.\n",
        "             \n",
        "             The best way to tempt the old to go on working may be to build on such ‘bridge’ jobs: part-time \n",
        "             or temporary employment that creates a more gradual transition from full-time work to retirement. \n",
        "             Studies have found that, in the United States, nearly half of all men and women who had been in \n",
        "             full-time jobs in middle age moved into such ‘bridge’ jobs at the end of their working lives. \n",
        "             In general, it is the best-paid and worst-paid who carry on working. There seem to be two very \n",
        "             different types of bridge job-holder –those who continue working because they have to and those \n",
        "             who continue working because they want to, even though theycould afford to retire.\n",
        "             \n",
        "             If the job market grows more flexible, the old may find more jobs that suit them. \n",
        "             Often, they will be self-employed. Sometimes, they may start their own businesses: a study by \n",
        "             David Storey of Warwick University found that in Britain 70% of businesses started by people over \n",
        "             55 survived, compared with an overall national average of only 19%. But whatever pattern of \n",
        "             employment they choose, in the coming years the skills of these ‘grey workers’ will have to be \n",
        "             increasingly acknowledgedand rewarded.\"\"\"\n",
        "\n",
        "answers = ['abolishing pay schemes that are based on age',\n",
        "           'allows the expertise of older workers to be put to use',\n",
        "           'appeal to distinct groups of older workers',\n",
        "           'older people are good at running their own businesses']\n",
        "\n",
        "true_questions = ['The writer suggests that companies could consider...',\n",
        "                  'Skill Team is an example of a company which...',\n",
        "                  'According to the writer, \"bridge\" jobs...',\n",
        "                  'David Storey\\'s study found that...']\n",
        "\n",
        "for i,answer in enumerate(answers):\n",
        "    print('answer: ' + answer)\n",
        "    print(generator.generate(context, answer))\n",
        "    print('true question: ' + true_questions[i] + '\\n')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "answer: abolishing pay schemes that are based on age\n",
            "question: What is the best way to tempt the old to work?\n",
            "true question: The writer suggests that companies could consider...\n",
            "\n",
            "answer: allows the expertise of older workers to be put to use\n",
            "question: What does the Skill Team do?\n",
            "true question: Skill Team is an example of a company which...\n",
            "\n",
            "answer: appeal to distinct groups of older workers\n",
            "question: What may mean employing older workers in different ways?\n",
            "true question: According to the writer, \"bridge\" jobs...\n",
            "\n",
            "answer: older people are good at running their own businesses\n",
            "question: What is the general assumption about older workers?\n",
            "true question: David Storey's study found that...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJpm1sbvpdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}