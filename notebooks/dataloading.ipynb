{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataloading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYhnE2lTKsAtW4G2CBAsZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vegarab/msc-qg/blob/master/notebooks/dataloading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVgSDTMEGKZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import json\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u4XxYFbI7Ci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2b514e30-a079-458f-e82e-28bd2429c965"
      },
      "source": [
        "!curl -LO https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 40.1M  100 40.1M    0     0  36.9M      0  0:00:01  0:00:01 --:--:-- 36.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu1sKUKbSDwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EOS_FORMATS = {\n",
        "    't5': '</s>'\n",
        "}\n",
        "\n",
        "def add_eos_to_input(_input, model='t5'):\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCVl-gXSGZoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SQUADDataset(Dataset):\n",
        "    def __init__(self, config, tokenizer, datafile):\n",
        "        self.config = config\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.data = self._squad_json_to_dataframe(datafile)\n",
        "\n",
        "        self.question = self.data.question\n",
        "        self.context = self.data.context\n",
        "        self.answer = self.data.answer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.question)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # TODO: Setup strings based on model\n",
        "        answer = str(self.answer[index]))\n",
        "        answer = ' '.join(answer.split())\n",
        "        answer = 'answer: ' + answer\n",
        "\n",
        "        context = str(self.context[index]))\n",
        "        context = ' '.join(context.split())\n",
        "        context = 'context: ' + context\n",
        "\n",
        "        _input = answer + ' <sep> ' + context + ' </s>'\n",
        "\n",
        "        question = str(self.question[index]))\n",
        "        question = ' '.join(question.split())\n",
        "\n",
        "        _output = question + ' </s'\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([_input],\n",
        "                                                  max_length=self.config.source_len,\n",
        "                                                  pad_to_max_length=True\n",
        "                                                  return_tensors='pt')\n",
        "\n",
        "        target = self.tokenizer.batch_encode_plus([_output],\n",
        "                                                  max_length=self.config.q_len,\n",
        "                                                  pad_to_max_length=True,\n",
        "                                                  return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['target_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "\n",
        "        return {\n",
        "            'source_ids', source_ids.to(dtype=torch.long),\n",
        "            'source_mask', source_mask.to(dtype=torch.long),\n",
        "            'target_ids', target_ids.to(dtype=torch.long),\n",
        "            'target_mask', target_mask.to(dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    \n",
        "    def _squad_json_to_dataframe(self, datafile):\n",
        "        '''\n",
        "        datafile: path to the squad json file.\n",
        "        '''\n",
        "        _file = json.loads(open(datafile).read())\n",
        "        _record_path = ['data', 'paragraphs', 'qas', 'answers']\n",
        "\n",
        "        # Parsing different levels in the JSON file\n",
        "        answers = pd.json_normalize(_file, _record_path)\n",
        "        questions = pd.json_normalize(_file, _record_path[:-1])\n",
        "        contexts = pd.json_normalize(_file, _record_path[:-2])\n",
        "\n",
        "        # Repeating context according to IDs for each question\n",
        "        idx = np.repeat(contexts['context'].values, contexts['qas'].str.len())\n",
        "        ndx  = np.repeat(questions['id'].values, questions['answers'].str.len())\n",
        "        questions['context'] = idx\n",
        "        answers['q_idx'] = ndx\n",
        "\n",
        "        # Merge all of this, using the newly created index\n",
        "        main = pd.concat([questions[['id', 'question','context', 'answers']].set_index('id'),\n",
        "                          answers.set_index('q_idx')],\n",
        "                         1, sort=False).reset_index()\n",
        "        main['c_id'] = main['context'].factorize()[0]\n",
        "\n",
        "        # Only use necessary columns and set appropriate names\n",
        "        main = main[['index', 'question', 'context', 'text', 'answer_start']]\n",
        "        main.rename(columns={'text':'answer'}, inplace=True)\n",
        "\n",
        "        return main\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mk86Y54HGNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = SQUADDataset(None, None, 'train-v2.0.json')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwS_dq0xJLwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "5bf01598-a2e2-466e-e750-17ddac5d6497"
      },
      "source": [
        "dataset.data.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_start</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>269.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>207.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>2003</td>\n",
              "      <td>526.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>166.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      index  ... answer_start\n",
              "0  56be85543aeaaa14008c9063  ...        269.0\n",
              "1  56be85543aeaaa14008c9065  ...        207.0\n",
              "2  56be85543aeaaa14008c9066  ...        526.0\n",
              "3  56bf6b0f3aeaaa14008c9601  ...        166.0\n",
              "4  56bf6b0f3aeaaa14008c9602  ...        276.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6PZ7DrgVWj5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc9i2Di9VWdy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}